{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Contributor: Akash Yadav"
      ],
      "metadata": {
        "id": "hlpPLtOy5-XG"
      },
      "id": "hlpPLtOy5-XG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUaCeCF9_3kQ"
      },
      "source": [
        "# GESIS Eurobarometer bulk downloader (≤ 2015) — Datasets → Purpose-of-use → Stata `.dta`\n",
        "\n",
        "This notebook implements the flow confirmed with your screenshots:\n",
        "\n",
        "1. From the **GESIS Eurobarometer study overview**, collect projects with year ≤ 2015.\n",
        "2. For each project page:\n",
        "   - Prefer **\"Study description\"** link.\n",
        "   - If missing, fall back to the **DOI** in the remarks.\n",
        "3. Resolve to the **GESIS Search dataset page** (`https://search.gesis.org/research_data/...`).\n",
        "4. On the dataset page:\n",
        "   - Open **Downloads → Datasets**.\n",
        "   - Select the purpose from the dropdown: **\"for further education and qualification\"**.\n",
        "   - Then click only **Stata `.dta`** items to download.\n",
        "\n",
        "Downloads go to `./downloads/ZAxxxx/` and a resume-friendly manifest is written to:\n",
        "`./downloads/download_manifest_le_2016.csv`\n",
        "\n",
        "**Credentials** are requested at runtime and stored only in RAM.\n",
        "\n",
        "Headless mode is enabled by default (needed if no X server / DISPLAY).\n"
      ],
      "id": "EUaCeCF9_3kQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkYW5q4P_3kR"
      },
      "outputs": [],
      "source": [
        "# Install dependencies (run once), then restart the kernel.\n",
        "!pip -q install playwright beautifulsoup4 lxml tqdm requests\n",
        "\n",
        "# Install Chromium + system deps\n",
        "!python -m playwright install --with-deps chromium\n"
      ],
      "id": "TkYW5q4P_3kR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Czt4Qvtw_3kR"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import csv\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from getpass import getpass\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Tuple\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from playwright.async_api import async_playwright, TimeoutError as PWTimeoutError\n",
        "\n",
        "STUDY_OVERVIEW_URL = (\n",
        "    \"https://www.gesis.org/en/eurobarometer-data-service/data-and-documentation/\"\n",
        "    \"standard-special-eb/study-overview\"\n",
        ")\n",
        "\n",
        "YEAR_CUTOFF = 2015\n",
        "\n",
        "PURPOSE_CANDIDATES = [\n",
        "    \"for further education and qualification\",\n",
        "    \"For further education and qualification\",\n",
        "    \"zur weiteren Ausbildung und Qualifikation\",\n",
        "]\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "DOWNLOAD_ROOT = Path(\"/content/drive/MyDrive/gesis_downloads\").resolve()\n",
        "DOWNLOAD_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MANIFEST = DOWNLOAD_ROOT / f\"download_manifest_le_{YEAR_CUTOFF}.csv\"\n",
        "\n",
        "print(\"DOWNLOAD_ROOT:\", DOWNLOAD_ROOT)\n",
        "print(\"MANIFEST:\", MANIFEST)\n",
        "\n",
        "UA = (\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
        "    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "    \"Chrome/120.0 Safari/537.36\"\n",
        ")\n",
        "\n",
        "session = requests.Session()\n",
        "session.headers.update({\"User-Agent\": UA})\n",
        "\n",
        "DOI_RE = re.compile(r\"\\b10\\.\\d{4,9}/\\S+\\b\")\n",
        "DTA_RE = re.compile(r\"\\.dta(?:$|[?#]|\\s|\\))\", re.I)\n",
        "\n",
        "@dataclass\n",
        "class EBProject:\n",
        "    title: str\n",
        "    project_url: str\n",
        "    year: int\n",
        "    za_id: Optional[str]\n",
        "    doi_url: Optional[str] = None\n",
        "    dataset_url: Optional[str] = None\n",
        "\n",
        "def _abs_url(base: str, href: str) -> str:\n",
        "    return requests.compat.urljoin(base, href)\n",
        "\n",
        "def extract_year(text: str) -> Optional[int]:\n",
        "    years = re.findall(r\"\\b(19\\d{2}|20\\d{2})\\b\", text)\n",
        "    return int(years[-1]) if years else None\n",
        "\n",
        "def extract_za_id(text: str) -> Optional[str]:\n",
        "    m = re.search(r\"\\bZA\\s*No\\.?\\s*(\\d{3,5})\\b\", text)\n",
        "    if m:\n",
        "        return f\"ZA{m.group(1)}\"\n",
        "    m2 = re.search(r\"\\bZA\\s*(\\d{3,5})\\b\", text)\n",
        "    if m2:\n",
        "        return f\"ZA{m2.group(1)}\"\n",
        "    return None\n",
        "\n",
        "def list_projects_from_overview() -> List[EBProject]:\n",
        "    r = session.get(STUDY_OVERVIEW_URL, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    soup = BeautifulSoup(r.text, \"lxml\")\n",
        "\n",
        "    projects: List[EBProject] = []\n",
        "    for a in soup.select(\"a[href]\"):\n",
        "        title = (a.get_text(\" \", strip=True) or \"\").strip()\n",
        "        if not title.startswith(\"Eurobarometer\"):\n",
        "            continue\n",
        "        if \"ZA\" not in title:\n",
        "            continue\n",
        "        href = a.get(\"href\")\n",
        "        if not href:\n",
        "            continue\n",
        "        url = _abs_url(STUDY_OVERVIEW_URL, href)\n",
        "        yr = extract_year(title)\n",
        "        if yr is None:\n",
        "            continue\n",
        "        za = extract_za_id(title)\n",
        "        projects.append(EBProject(title=title, project_url=url, year=yr, za_id=za))\n",
        "\n",
        "    return list({p.project_url: p for p in projects}.values())\n",
        "\n",
        "def get_dataset_or_doi_from_project_page(project_url: str) -> Tuple[Optional[str], Optional[str]]:\n",
        "    \"\"\"Return (dataset_url, doi_url) from a project page.\n",
        "    Prefer 'Study description'; else DOI hyperlink; else DOI text.\n",
        "    \"\"\"\n",
        "    r = session.get(project_url, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    soup = BeautifulSoup(r.text, \"lxml\")\n",
        "\n",
        "    for a in soup.select(\"a[href]\"):\n",
        "        txt = (a.get_text(\" \", strip=True) or \"\").strip().lower()\n",
        "        if \"study description\" in txt:\n",
        "            return (_abs_url(project_url, a[\"href\"].strip()), None)\n",
        "\n",
        "    for a in soup.select(\"a[href]\"):\n",
        "        href = a[\"href\"].strip()\n",
        "        if \"doi.org/\" in href or \"dx.doi.org/\" in href:\n",
        "            return (None, _abs_url(project_url, href))\n",
        "\n",
        "    text = soup.get_text(\" \", strip=True)\n",
        "    m = DOI_RE.search(text)\n",
        "    if m:\n",
        "        return (None, f\"https://doi.org/{m.group(0)}\")\n",
        "\n",
        "    return (None, None)\n",
        "\n",
        "def resolve_to_final_url(url: str) -> str:\n",
        "    r = session.get(url, allow_redirects=True, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    return r.url\n",
        "\n",
        "projects = list_projects_from_overview()\n",
        "targets = sorted([p for p in projects if p.year <= YEAR_CUTOFF], key=lambda x: (x.year, x.title))\n",
        "print(f\"Found {len(targets)} Eurobarometer projects with year <= {YEAR_CUTOFF}.\")\n",
        "targets[:5]\n"
      ],
      "id": "Czt4Qvtw_3kR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1eIecRw_3kS"
      },
      "outputs": [],
      "source": [
        "resolved: List[EBProject] = []\n",
        "for p in tqdm(targets, desc=\"Resolving dataset URLs from project pages\"):\n",
        "    try:\n",
        "        dataset_url, doi_url = get_dataset_or_doi_from_project_page(p.project_url)\n",
        "        if dataset_url:\n",
        "            p.dataset_url = resolve_to_final_url(dataset_url)\n",
        "        elif doi_url:\n",
        "            p.doi_url = doi_url\n",
        "            p.dataset_url = resolve_to_final_url(doi_url)\n",
        "        else:\n",
        "            p.dataset_url = None\n",
        "\n",
        "        if p.dataset_url:\n",
        "            resolved.append(p)\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "targets = resolved\n",
        "print(\"Targets with resolved dataset_url:\", len(targets))\n",
        "print(\"Example dataset_url:\", targets[0].dataset_url if targets else \"(none)\")\n"
      ],
      "id": "Z1eIecRw_3kS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLiT5ctM_3kS"
      },
      "outputs": [],
      "source": [
        "def manifest_has(za_id: str, filename: str) -> bool:\n",
        "    if not MANIFEST.exists():\n",
        "        return False\n",
        "    with MANIFEST.open(\"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            if row.get(\"za_id\") == za_id and row.get(\"filename\") == filename and row.get(\"status\") == \"ok\":\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "def append_manifest(row: dict):\n",
        "    exists = MANIFEST.exists()\n",
        "    with MANIFEST.open(\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        fieldnames = [\"timestamp\", \"za_id\", \"study_title\", \"dataset_url\", \"filename\", \"saved_to\", \"status\", \"note\"]\n",
        "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        if not exists:\n",
        "            w.writeheader()\n",
        "        w.writerow(row)\n",
        "\n",
        "async def accept_cookies_if_present(page):\n",
        "    for txt in [\"Accept all\", \"Accept\", \"I agree\", \"Agree\", \"Alle akzeptieren\", \"Akzeptieren\"]:\n",
        "        try:\n",
        "            loc = page.get_by_role(\"button\", name=re.compile(rf\"^{re.escape(txt)}$\", re.I))\n",
        "            if await loc.count() > 0 and await loc.first.is_visible():\n",
        "                await loc.first.click(timeout=1500)\n",
        "                break\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "async def is_logged_in(page, email_hint: str | None = None) -> bool:\n",
        "    # Best-effort heuristics\n",
        "    try:\n",
        "        # Many pages show the user/email in the top bar when logged in\n",
        "        if email_hint:\n",
        "            if await page.locator(f\"text={email_hint}\").count() > 0:\n",
        "                return True\n",
        "        # Sometimes there is a logout button/link\n",
        "        if await page.locator(\"a:has-text('Logout'), a:has-text('Log out'), a:has-text('Abmelden')\").count() > 0:\n",
        "            return True\n",
        "    except Exception:\n",
        "        pass\n",
        "    return False\n",
        "\n",
        "\n",
        "async def ensure_logged_in(page, email: str, password: str):\n",
        "    if await is_logged_in(page, email_hint=email):\n",
        "        return\n",
        "\n",
        "    # Try to find an actual login link and navigate to its href (more reliable than click in headless)\n",
        "    login_href = None\n",
        "    try:\n",
        "        cand = page.locator(\"a:has-text('Login'), a:has-text('Log in')\").first\n",
        "        if await cand.count() > 0:\n",
        "            login_href = await cand.get_attribute(\"href\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    if login_href:\n",
        "        try:\n",
        "            await page.goto(login_href, wait_until=\"domcontentloaded\")\n",
        "        except Exception:\n",
        "            pass\n",
        "    else:\n",
        "        # fallback: click and hope it navigates\n",
        "        try:\n",
        "            await page.locator(\"a:has-text('Login'), a:has-text('Log in'), button:has-text('Login'), button:has-text('Log in')\").first.click(timeout=8000)\n",
        "            await page.wait_for_timeout(1500)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # If on SSO/login domain, fill credentials\n",
        "    if is_login_page_url(page.url):\n",
        "        await login_if_needed(page, email, password)\n",
        "\n",
        "    # wait briefly for session to settle\n",
        "    await page.wait_for_timeout(2000)\n",
        "\n",
        "async def open_datasets_dialog(page):\n",
        "    # Ensure the right-side Downloads box is present (best-effort)\n",
        "    try:\n",
        "        await page.locator(\"text=Downloads\").first.wait_for(timeout=8000)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Try multiple ways to click \"Datasets\"\n",
        "    clicked = False\n",
        "    clickers = [\n",
        "        lambda: page.get_by_role(\"link\", name=re.compile(r\"^Datasets$\", re.I)).click(timeout=15000),\n",
        "        lambda: page.get_by_role(\"button\", name=re.compile(r\"^Datasets$\", re.I)).click(timeout=15000),\n",
        "        lambda: page.locator(\"a:has-text('Datasets')\").first.click(timeout=15000),\n",
        "        lambda: page.locator(\"text=Datasets\").first.click(timeout=15000),\n",
        "        lambda: page.locator(\"div:has-text('Downloads') a:has-text('Datasets')\").first.click(timeout=15000),\n",
        "    ]\n",
        "    for fn in clickers:\n",
        "        try:\n",
        "            await fn()\n",
        "            clicked = True\n",
        "            break\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    if not clicked:\n",
        "        raise TimeoutError(\"Could not click 'Datasets' in the Downloads panel\")\n",
        "\n",
        "    # Wait for the modal dialog to appear\n",
        "    dialog = page.locator(\"div[role='dialog']\").filter(\n",
        "        has_text=re.compile(r\"Download datasets\", re.I)\n",
        "    ).first\n",
        "    await dialog.wait_for(state=\"visible\", timeout=15000)\n",
        "    return dialog\n",
        "\n",
        "async def ensure_purpose_selected(dialog):\n",
        "    \"\"\"\n",
        "    Select purpose-of-use inside the 'Download datasets' modal dialog.\n",
        "    Must be called AFTER open_datasets_dialog().\n",
        "    \"\"\"\n",
        "    # 1) native <select> inside modal (your screenshots show a select dropdown)\n",
        "    try:\n",
        "        sel = dialog.locator(\"select\").first\n",
        "        await sel.wait_for(state=\"visible\", timeout=5000)\n",
        "        for purpose in PURPOSE_CANDIDATES:\n",
        "            try:\n",
        "                await sel.select_option(label=purpose)\n",
        "                return True\n",
        "            except Exception:\n",
        "                continue\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 2) fallback: combobox-style dropdown inside modal\n",
        "    try:\n",
        "        combo = dialog.get_by_role(\"combobox\")\n",
        "        if await combo.count() > 0:\n",
        "            await combo.first.click(timeout=3000)\n",
        "            for purpose in PURPOSE_CANDIDATES:\n",
        "                opt = dialog.get_by_role(\"option\", name=re.compile(re.escape(purpose), re.I))\n",
        "                if await opt.count() > 0:\n",
        "                    await opt.first.click(timeout=3000)\n",
        "                    return True\n",
        "                t = dialog.locator(f\"text={purpose}\")\n",
        "                if await t.count() > 0:\n",
        "                    await t.first.click(timeout=3000)\n",
        "                    return True\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return False\n",
        "\n",
        "async def handle_purpose_dialog(page):\n",
        "    try:\n",
        "        prompt_loc = page.locator(\"text=Please specify a purpose\")\n",
        "        if await prompt_loc.count() == 0:\n",
        "            prompt_loc = page.locator(\"text=Bitte geben Sie einen Zweck\")\n",
        "        if await prompt_loc.count() == 0:\n",
        "            return\n",
        "        if not await prompt_loc.first.is_visible(timeout=1500):\n",
        "            return\n",
        "    except Exception:\n",
        "        return\n",
        "\n",
        "    for purpose in PURPOSE_CANDIDATES:\n",
        "        try:\n",
        "            loc = page.locator(f\"text={purpose}\")\n",
        "            if await loc.count() > 0:\n",
        "                await loc.first.click(timeout=1500)\n",
        "                break\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    for lab in [\n",
        "        \"I agree to the Terms of Use\",\n",
        "        \"I agree to the terms of use\",\n",
        "        \"Ich stimme den Nutzungsbedingungen zu\",\n",
        "        \"I have read and accept\",\n",
        "    ]:\n",
        "        try:\n",
        "            cb = page.get_by_label(lab)\n",
        "            if await cb.count() > 0 and await cb.first.is_visible():\n",
        "                await cb.first.check()\n",
        "                break\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    for btn in [\"Download\", \"Start download\", \"Continue\", \"OK\", \"Confirm\", \"Proceed\", \"Submit\", \"Fortfahren\", \"Herunterladen\"]:\n",
        "        try:\n",
        "            b = page.get_by_role(\"button\", name=re.compile(btn, re.I))\n",
        "            if await b.count() > 0 and await b.first.is_visible():\n",
        "                await b.first.click()\n",
        "                break\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "async def discover_dta_click_targets(dialog, base_url: str):\n",
        "    \"\"\"\n",
        "    Returns list of dicts:\n",
        "      [{\"fname\": \"...dta\", \"href\": \"https://...\", \"idx\": <index in filtered locator>}]\n",
        "    Works even if the site uses JS / data-attributes for URLs.\n",
        "    Skips disabled/greyed-out items.\n",
        "    \"\"\"\n",
        "    loc = dialog.locator(\"a\").filter(has_text=re.compile(r\"\\.dta\\b\", re.I))\n",
        "    n = await loc.count()\n",
        "    items = []\n",
        "\n",
        "    for i in range(n):\n",
        "        a = loc.nth(i)\n",
        "\n",
        "        info = await a.evaluate(\"\"\"\n",
        "            el => ({\n",
        "                text: (el.innerText || '').trim(),\n",
        "                hrefProp: el.href || '',\n",
        "                hrefAttr: el.getAttribute('href') || '',\n",
        "                ariaDisabled: el.getAttribute('aria-disabled') || '',\n",
        "                className: el.className || '',\n",
        "                dataHref: (el.dataset && (el.dataset.href || el.dataset.url || el.dataset.download || el.dataset.downloadUrl)) || ''\n",
        "            })\n",
        "        \"\"\")\n",
        "\n",
        "        aria_disabled = (info.get(\"ariaDisabled\") or \"\").lower()\n",
        "        cls = (info.get(\"className\") or \"\").lower()\n",
        "        if aria_disabled == \"true\" or \"disabled\" in cls:\n",
        "            continue\n",
        "\n",
        "        href = (info.get(\"hrefProp\") or \"\").strip()\n",
        "        if not href:\n",
        "            href = (info.get(\"dataHref\") or \"\").strip()\n",
        "        if not href:\n",
        "            href = (info.get(\"hrefAttr\") or \"\").strip()\n",
        "\n",
        "        if (not href) or href.startswith(\"#\") or href.lower().startswith(\"javascript:\"):\n",
        "            continue\n",
        "\n",
        "        href_abs = urljoin(base_url, href)\n",
        "\n",
        "        m = re.search(r\"([^/?#]+\\.dta)\\b\", href_abs, re.I)\n",
        "        if m:\n",
        "            fname = m.group(1)\n",
        "        else:\n",
        "            text = info.get(\"text\") or \"\"\n",
        "            m2 = re.search(r\"([A-Za-z0-9_\\-]+\\.dta)\\b\", text, re.I)\n",
        "            fname = m2.group(1) if m2 else f\"file_{i}.dta\"\n",
        "\n",
        "        items.append({\"fname\": fname, \"href\": href_abs, \"idx\": i})\n",
        "\n",
        "    # de-dup by href\n",
        "    dedup = {}\n",
        "    for it in items:\n",
        "        dedup[it[\"href\"]] = it\n",
        "    return [dedup[k] for k in sorted(dedup.keys())]\n",
        "\n",
        "async def close_dialog(dialog, page):\n",
        "    # Try the X button in the modal header\n",
        "    try:\n",
        "        btn = dialog.locator(\"button\").filter(has=dialog.locator(\"svg\")).first\n",
        "        if await btn.count() > 0:\n",
        "            await btn.click(timeout=2000)\n",
        "            return\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Fallbacks\n",
        "    try:\n",
        "        await page.keyboard.press(\"Escape\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "print(\"Manifest path:\", MANIFEST)\n"
      ],
      "id": "ZLiT5ctM_3kS"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FULL MAIN DOWNLOAD LOOP (REQUEST-BASED, MODAL-SCOPED) ---\n",
        "\n",
        "gesis_email = input(\"GESIS login email: \").strip()\n",
        "gesis_password = getpass(\"GESIS password (input hidden): \")\n",
        "\n",
        "HEADLESS = True  # Colab: keep True\n",
        "\n",
        "async def run_all():\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=HEADLESS)\n",
        "        context = await browser.new_context(accept_downloads=True)\n",
        "        page = await context.new_page()\n",
        "\n",
        "        # warm-up\n",
        "        await page.goto(\"https://search.gesis.org/\", wait_until=\"domcontentloaded\")\n",
        "        await accept_cookies_if_present(page)\n",
        "\n",
        "        # proactive login once\n",
        "        try:\n",
        "            await ensure_logged_in(page, gesis_email, gesis_password)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        for proj in tqdm(targets, desc=f\"Downloading EB studies <= {YEAR_CUTOFF}\"):\n",
        "            za_dir = DOWNLOAD_ROOT / (proj.za_id or \"ZA_UNKNOWN\")\n",
        "            za_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            if not getattr(proj, \"dataset_url\", None):\n",
        "                append_manifest({\n",
        "                    \"timestamp\": datetime.utcnow().isoformat(),\n",
        "                    \"za_id\": proj.za_id or \"(unknown)\",\n",
        "                    \"study_title\": proj.title,\n",
        "                    \"dataset_url\": \"(none)\",\n",
        "                    \"filename\": \"(none)\",\n",
        "                    \"saved_to\": \"(none)\",\n",
        "                    \"status\": \"skip\",\n",
        "                    \"note\": \"No dataset_url resolved\",\n",
        "                })\n",
        "                continue\n",
        "\n",
        "            dialog = None\n",
        "            try:\n",
        "                # 1) open the dataset landing page\n",
        "                await page.goto(proj.dataset_url, wait_until=\"networkidle\")\n",
        "                await accept_cookies_if_present(page)\n",
        "\n",
        "                # 2) ensure logged in (important: may not redirect automatically)\n",
        "                await ensure_logged_in(page, gesis_email, gesis_password)\n",
        "\n",
        "                # If still on login URL after ensure, do manual completion\n",
        "                if is_login_page_url(page.url):\n",
        "                    await login_if_needed(page, gesis_email, gesis_password)\n",
        "                    await page.goto(proj.dataset_url, wait_until=\"networkidle\")\n",
        "                    await accept_cookies_if_present(page)\n",
        "\n",
        "                # 3) open modal: Downloads → Datasets\n",
        "                dialog = await open_datasets_dialog(page)\n",
        "\n",
        "                # If modal itself says login required, re-login and reopen\n",
        "                if await dialog.locator(\"text=requires a login\").count() > 0:\n",
        "                    await close_dialog(dialog, page)\n",
        "                    await ensure_logged_in(page, gesis_email, gesis_password)\n",
        "                    await page.goto(proj.dataset_url, wait_until=\"networkidle\")\n",
        "                    dialog = await open_datasets_dialog(page)\n",
        "\n",
        "                # 4) select purpose INSIDE modal\n",
        "                ok = await ensure_purpose_selected(dialog)\n",
        "                if not ok:\n",
        "                    await page.screenshot(path=str(za_dir / \"debug_no_purpose_dropdown.png\"), full_page=True)\n",
        "                    append_manifest({\n",
        "                        \"timestamp\": datetime.utcnow().isoformat(),\n",
        "                        \"za_id\": proj.za_id or \"(unknown)\",\n",
        "                        \"study_title\": proj.title,\n",
        "                        \"dataset_url\": proj.dataset_url,\n",
        "                        \"filename\": \"(none)\",\n",
        "                        \"saved_to\": \"(none)\",\n",
        "                        \"status\": \"error\",\n",
        "                        \"note\": \"Purpose dropdown not found/selected. Likely not logged in. See debug_no_purpose_dropdown.png\",\n",
        "                    })\n",
        "                    await close_dialog(dialog, page)\n",
        "                    await page.wait_for_timeout(300)\n",
        "                    continue\n",
        "\n",
        "                await page.wait_for_timeout(800)\n",
        "\n",
        "                # 5) find *valid* .dta links INSIDE modal\n",
        "                dta_items = await discover_dta_click_targets(dialog, page.url)\n",
        "\n",
        "                if not dta_items:\n",
        "                    await page.screenshot(path=str(za_dir / \"debug_no_dta_links.png\"), full_page=True)\n",
        "                    append_manifest({\n",
        "                        \"timestamp\": datetime.utcnow().isoformat(),\n",
        "                        \"za_id\": proj.za_id or \"(unknown)\",\n",
        "                        \"study_title\": proj.title,\n",
        "                        \"dataset_url\": proj.dataset_url,\n",
        "                        \"filename\": \"(none)\",\n",
        "                        \"saved_to\": \"(none)\",\n",
        "                        \"status\": \"warn\",\n",
        "                        \"note\": \"No enabled .dta links in modal (still greyed?). See debug_no_dta_links.png\",\n",
        "                    })\n",
        "                    await close_dialog(dialog, page)\n",
        "                    await page.wait_for_timeout(300)\n",
        "                    continue\n",
        "\n",
        "                # 6) download each file (request-first; click-fallback; DO NOT save HTML)\n",
        "                for it in dta_items:\n",
        "                    filename = it[\"fname\"]\n",
        "                    href = it[\"href\"]\n",
        "                    idx = it[\"idx\"]\n",
        "\n",
        "                    if proj.za_id and manifest_has(proj.za_id, filename):\n",
        "                        continue\n",
        "\n",
        "                    try:\n",
        "                        used = None\n",
        "\n",
        "                        # --- Attempt A: direct authenticated request ---\n",
        "                        resp = await context.request.get(\n",
        "                            href,\n",
        "                            timeout=180000,\n",
        "                            headers={\"Referer\": page.url}\n",
        "                        )\n",
        "\n",
        "                        if resp.ok:\n",
        "                            data = await resp.body()\n",
        "                            ct = (resp.headers.get(\"content-type\") or \"\").lower()\n",
        "                            head = data[:400].lstrip()\n",
        "\n",
        "                            is_html = (\"text/html\" in ct) or head.startswith(\n",
        "                                (b\"<!doctype html\", b\"<html\", b\"<head\", b\"<body\")\n",
        "                            )\n",
        "\n",
        "                            # If it's not HTML and looks like a file, save it\n",
        "                            if not is_html and len(data) > 1024:  # quick sanity threshold\n",
        "                                dest = za_dir / filename\n",
        "\n",
        "                                # avoid overwrite\n",
        "                                if dest.exists():\n",
        "                                    stem, suf = dest.stem, dest.suffix\n",
        "                                    j = 1\n",
        "                                    while (za_dir / f\"{stem}__{j}{suf}\").exists():\n",
        "                                        j += 1\n",
        "                                    dest = za_dir / f\"{stem}__{j}{suf}\"\n",
        "\n",
        "                                dest.write_bytes(data)\n",
        "                                used = \"request\"\n",
        "                            else:\n",
        "                                used = \"fallback\"  # request gave HTML/interstitial\n",
        "                        else:\n",
        "                            used = \"fallback\"  # non-200 / blocked\n",
        "\n",
        "                        # --- Attempt B: click-based download (browser-faithful) ---\n",
        "                        if used == \"fallback\":\n",
        "                            # re-locate the same anchor inside the current modal\n",
        "                            link_loc = dialog.locator(\"a\").filter(has_text=re.compile(r\"\\.dta\\b\", re.I)).nth(idx)\n",
        "\n",
        "                            async with page.expect_download(timeout=180000) as di:\n",
        "                                await link_loc.click(button=\"left\", timeout=15000)\n",
        "\n",
        "                            download = await di.value\n",
        "                            real_name = download.suggested_filename or filename\n",
        "                            dest = za_dir / real_name\n",
        "\n",
        "                            # avoid overwrite\n",
        "                            if dest.exists():\n",
        "                                stem, suf = dest.stem, dest.suffix\n",
        "                                j = 1\n",
        "                                while (za_dir / f\"{stem}__{j}{suf}\").exists():\n",
        "                                    j += 1\n",
        "                                dest = za_dir / f\"{stem}__{j}{suf}\"\n",
        "\n",
        "                            await download.save_as(str(dest))\n",
        "                            filename = real_name  # for manifest\n",
        "\n",
        "                        append_manifest({\n",
        "                            \"timestamp\": datetime.utcnow().isoformat(),\n",
        "                            \"za_id\": proj.za_id or \"(unknown)\",\n",
        "                            \"study_title\": proj.title,\n",
        "                            \"dataset_url\": proj.dataset_url,\n",
        "                            \"filename\": filename,\n",
        "                            \"saved_to\": str(dest),\n",
        "                            \"status\": \"ok\",\n",
        "                            \"note\": f\"mode=B; used={used}; href={href}\",\n",
        "                        })\n",
        "\n",
        "                    except Exception as e:\n",
        "                        await page.screenshot(path=str(za_dir / \"debug_download_failed.png\"), full_page=True)\n",
        "                        append_manifest({\n",
        "                            \"timestamp\": datetime.utcnow().isoformat(),\n",
        "                            \"za_id\": proj.za_id or \"(unknown)\",\n",
        "                            \"study_title\": proj.title,\n",
        "                            \"dataset_url\": proj.dataset_url,\n",
        "                            \"filename\": filename,\n",
        "                            \"saved_to\": \"(none)\",\n",
        "                            \"status\": \"error\",\n",
        "                            \"note\": f\"Download failed: {repr(e)}\",\n",
        "                        })\n",
        "                # 7) close modal\n",
        "                if dialog is not None:\n",
        "                    await close_dialog(dialog, page)\n",
        "                    await page.wait_for_timeout(300)\n",
        "\n",
        "            except Exception as e:\n",
        "                try:\n",
        "                    if dialog is not None:\n",
        "                        await close_dialog(dialog, page)\n",
        "                        await page.wait_for_timeout(300)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "                append_manifest({\n",
        "                    \"timestamp\": datetime.utcnow().isoformat(),\n",
        "                    \"za_id\": proj.za_id or \"(unknown)\",\n",
        "                    \"study_title\": proj.title,\n",
        "                    \"dataset_url\": proj.dataset_url,\n",
        "                    \"filename\": \"(none)\",\n",
        "                    \"saved_to\": \"(none)\",\n",
        "                    \"status\": \"error\",\n",
        "                    \"note\": f\"Project-level failure: {repr(e)}\",\n",
        "                })\n",
        "\n",
        "        print(\"Done. Manifest saved to:\", MANIFEST)\n",
        "        await browser.close()\n",
        "\n",
        "await run_all()"
      ],
      "metadata": {
        "id": "a2exdF9zvvHb"
      },
      "id": "a2exdF9zvvHb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}